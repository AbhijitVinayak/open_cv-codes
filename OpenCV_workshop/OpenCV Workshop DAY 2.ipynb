{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"top\"></a>\n",
    "# OpenCV workshop Day 2\n",
    "\n",
    "Here's a documentation to OpenCV to assist you with the day 2 of the Workshop in OpenCV and Computer Vision. The codes are written \n",
    "\n",
    "![Computer](./cv.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"height:10px;\"></div>\n",
    "\n",
    "- [OpenCV documentation and Tutorials](#-open-cv-documentation)\n",
    "- [Projects in openCV and Computer Vision](#-projects)\n",
    "- [Colour Spaces and Thresholding](#-colour-spaces)\n",
    "- [Filters](#-filters)\n",
    "- [Canny Edge Detection](#-canny-edge-detection)\n",
    "- [Face Detection](#-face-detection)\n",
    "- [Further Resources](#-other)\n",
    "\n",
    "\n",
    "<div style=\"height:10px;\"></div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b id=\"-open-cv-documentation\">OpenCV documentation and Tutorials</b> <a href=\"#top\">[back to top]</a>\n",
    "\n",
    "\n",
    "- Official OpenCV documentation - The Bible for OpenCV[[here](https://docs.opencv.org/2.4/doc/tutorials/tutorials.html)]\n",
    " \n",
    " Refer to the official openCV documentation above for detailed tutorials.\n",
    " \n",
    "\n",
    "\n",
    "<br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b id=\"-projects\">Projects in openCV and Computer Vision</b> <a href=\"#top\">[back to top]</a>\n",
    "\n",
    "- Great projects for all levels. From basic image processing to Machine Learning [[Hackster](https://www.hackster.io/opencv/projects)]  \n",
    "\n",
    "Don't be intimidated !!! Start working on the basic projects to get a hang of it and eventually dive into deep learning for Computer Vision. <br><br>\n",
    "![LearnDo](./learnbydoing.jpg)\n",
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b id=\"-colour-spaces\">Colour Spaces and Thresholding</b> <a href=\"#top\">[back to top]</a>\n",
    "\n",
    "- Interested in knowing the mathematics behind color conversions from one form of representation to another? Have a look at this brief explanation. Do not worry if you don't understand it on the first go . [[Math of Color Conversion](https://docs.opencv.org/3.1.0/de/d25/imgproc_color_conversions.html)]  \n",
    "\n",
    "![BlueMask](./bluemask.jpg)\n",
    "![YellowMask](./yellowmask.jpg)\n",
    "\n",
    "REFER TO THE CODE BELOW FOR CONVERTING AN IMAGE FROM RGB TO GRAYSCALE :\n",
    "\n",
    "![IronMan](./ironman.png)\n",
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Could not create write struct",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/home/akshatha_kamath/anaconda2/lib/python2.7/site-packages/IPython/core/formatters.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    332\u001b[0m                 \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    333\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 334\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mprinter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    335\u001b[0m             \u001b[0;31m# Finally look for special method names\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    336\u001b[0m             \u001b[0mmethod\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_real_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprint_method\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/akshatha_kamath/anaconda2/lib/python2.7/site-packages/IPython/core/pylabtools.pyc\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(fig)\u001b[0m\n\u001b[1;32m    245\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    246\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;34m'png'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mformats\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 247\u001b[0;31m         \u001b[0mpng_formatter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfor_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mFigure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mfig\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mprint_figure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'png'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    248\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;34m'retina'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mformats\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m'png2x'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mformats\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    249\u001b[0m         \u001b[0mpng_formatter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfor_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mFigure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mfig\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mretina_figure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/akshatha_kamath/anaconda2/lib/python2.7/site-packages/IPython/core/pylabtools.pyc\u001b[0m in \u001b[0;36mprint_figure\u001b[0;34m(fig, fmt, bbox_inches, **kwargs)\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m     \u001b[0mbytes_io\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBytesIO\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m     \u001b[0mfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcanvas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprint_figure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbytes_io\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbytes_io\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetvalue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfmt\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'svg'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/akshatha_kamath/anaconda2/lib/python2.7/site-packages/matplotlib/backend_bases.pyc\u001b[0m in \u001b[0;36mprint_figure\u001b[0;34m(self, filename, dpi, facecolor, edgecolor, orientation, format, **kwargs)\u001b[0m\n\u001b[1;32m   2210\u001b[0m                     \u001b[0morientation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morientation\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2211\u001b[0m                     \u001b[0mdryrun\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2212\u001b[0;31m                     **kwargs)\n\u001b[0m\u001b[1;32m   2213\u001b[0m                 \u001b[0mrenderer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cachedRenderer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2214\u001b[0m                 \u001b[0mbbox_inches\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_tightbbox\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrenderer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/akshatha_kamath/anaconda2/lib/python2.7/site-packages/matplotlib/backends/backend_agg.pyc\u001b[0m in \u001b[0;36mprint_png\u001b[0;34m(self, filename_or_obj, *args, **kwargs)\u001b[0m\n\u001b[1;32m    526\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mcbook\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen_file_cm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename_or_obj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"wb\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfh\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    527\u001b[0m                 _png.write_png(renderer._renderer, fh,\n\u001b[0;32m--> 528\u001b[0;31m                                self.figure.dpi, metadata=metadata)\n\u001b[0m\u001b[1;32m    529\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mrenderer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdpi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moriginal_dpi\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Could not create write struct"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import cv2\n",
    "from matplotlib import pyplot as plt\n",
    "# Load a color image\n",
    "img = cv2.imread('DL.jpeg',1)\n",
    "\n",
    "#convert RGB image to Gray\n",
    "gray=cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "#Display the gray image\n",
    "plt.imshow(gray)\n",
    "plt.show()\n",
    "\n",
    "#cv2.waitKey(0)\n",
    "#cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# import the necessary packages\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    " \n",
    "# load the image\n",
    "image = cv2.imread('mainimage.png',1)\n",
    "\n",
    "# define the list of boundaries\n",
    "boundaries = [\n",
    "\t([17, 15, 100], [50, 56, 200]),\n",
    "\t([86, 31, 4], [220, 88, 50]),\n",
    "\t([25, 146, 190], [62, 174, 250]),\n",
    "\t([103, 86, 65], [145, 133, 128])\n",
    "]\n",
    "\n",
    "\n",
    "# loop over the boundaries\n",
    "for (lower, upper) in boundaries:\n",
    "\t# create NumPy arrays from the boundaries\n",
    "\tlower = np.array(lower, dtype = \"uint8\")\n",
    "\tupper = np.array(upper, dtype = \"uint8\")\n",
    "\n",
    "\t# find the colors within the specified boundaries and apply\n",
    "\t# the mask\n",
    "\tmask = cv2.inRange(image, lower, upper)\n",
    "\toutput = cv2.bitwise_and(image, image, mask = mask)\n",
    "\n",
    "\t# show the images\n",
    "\tcv2.imshow(\"images\", np.hstack([image, output]))\n",
    "\tcv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b id=\"-filters\">Filters</b> <a href=\"#top\">[back to top]</a>\n",
    "\n",
    "- Read this tutorial from the official openCV documentation on Filtering techniques. [[Filters](https://opencv-python-tutroals.readthedocs.io/en/latest/py_tutorials/py_imgproc/py_filtering/py_filtering.html)]  \n",
    "\n",
    "![Median](./medianfilter.png)\n",
    " MEDIAN FILTER \n",
    " \n",
    " \n",
    "![GaussianBlur](./gaussianblur.jpg)\n",
    "GAUSSIAN BLUR \n",
    "\n",
    "\n",
    "![Bilateral](./bilateral.jpg)\n",
    "BILATERAL FILTER\n",
    "\n",
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b id=\"-canny-edge-detection\">Canny Edge Detection</b> <a href=\"#top\">[back to top]</a>\n",
    "\n",
    "- Canny Edge Detection is used to detect the edges in an image. It accepts a gray scale image as input and it uses a multistage algorithm.\n",
    "\n",
    "Don't be intimidated !!! Start working on the basic projects to get a hang of it and eventually dive into deep learning for Computer Vision. \n",
    "![Canny Edge](./canny.png)\n",
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b id=\"-face-detection\">Face Detection</b> <a href=\"#top\">[back to top]</a>\n",
    "\n",
    "- Great projects for all levels. From basic image processing to Machine Learning [[Hackster](https://www.hackster.io/opencv/projects)]  \n",
    "\n",
    "Don't be intimidated !!! Start working on the basic projects to get a hang of it and eventually dive into deep learning for Computer Vision. \n",
    "![Controller characteristics](../.DATA/Images/PIDController_Info.png)\n",
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b id=\"-others\">Further Resources</b> <a href=\"#top\">[back to top]</a>\n",
    "\n",
    "- This course is a deep dive into details of the deep learning architectures with a focus on learning end-to-end models for these tasks, particularly image classification. During the 10-week course, students will learn to implement, train and debug their own **neural networks** and gain a detailed understanding of cutting-edge research in computer vision. The final assignment will involve training a multi-million parameter convolutional neural network and applying it on the largest image classification dataset (ImageNet). We will focus on teaching how to set up the problem of image recognition, the learning algorithms (e.g. backpropagation), practical engineering tricks for training and fine-tuning the networks and guide the students through hands-on assignments and a final course project. Much of the background and materials of this course will be drawn from the ImageNet Challenge.[[Course](http://cs231n.stanford.edu/)] \n",
    "\n",
    "\n",
    "- The goal of this course is to introduce students to computer vision, starting from basics and then turning to more modern deep learning models. We will cover both image and video recognition, including image classification and annotation, object recognition and image search, various object detection techniques, motion estimation, object tracking in video, human action recognition, and finally image stylization, editing and new image generation. In course project, students will learn how to build face recognition and manipulation system to understand the internal mechanics of this technology, probably the most renown and oftenly demonstrated in movies and TV-shows example of computer vision and AI.[[CourseEra](https://www.coursera.org/learn/deep-learning-in-computer-vision)] \n",
    "\n",
    "![DeepLearning](./DL.jpeg)\n",
    "\n",
    "- Learning OpenCV puts you in the middle of the rapidly expanding field of computer vision. Written by the creators of the free open source OpenCV library, this book introduces you to computer vision and demonstrates how you can quickly build applications that enable computers to \"see\" and make decisions based on that data. \n",
    "    - This book includes:\n",
    "    - A thorough introduction to OpenCV\n",
    "    - Getting input from cameras\n",
    "    - Transforming images\n",
    "    - Segmenting images and shape matching\n",
    "    - Pattern recognition, including face detection\n",
    "    - Tracking and motion in 2 and 3 dimensions\n",
    "    - 3D reconstruction from stereo vision\n",
    "    - Machine learning algorithms\n",
    "    \n",
    "![TextBook](./opencv.jpg) \n",
    "\n",
    "![AICar](./aicar.jpg)\n",
    "\n",
    "<br>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
